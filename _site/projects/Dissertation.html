<h2 id="mnist-with-a-twist-learning-rotations-with-vaes">MNIST with a Twist: Learning Rotations with VAEs</h2>

<p>This project explores whether neural networks can learn the concept of “rotation” through a conditional Variational Autoencoder (VAE) trained on MNIST digit images.</p>

<h3 id="project-overview">Project Overview</h3>

<p>The conditional VAE was designed to:</p>
<ul>
  <li>Encode MNIST digits into a latent space</li>
  <li>Learn rotation as a manipulable variable in this space</li>
  <li>Generate new rotated versions of input digits</li>
</ul>

<h3 id="technical-implementation">Technical Implementation</h3>

<ul>
  <li><strong>Architecture</strong>: Conditional VAE with rotation encoding</li>
  <li><strong>Dataset</strong>: Modified MNIST with rotated versions of digits</li>
  <li><strong>Training</strong>: [Brief description of training process]</li>
  <li><strong>Evaluation</strong>: [How you evaluated the model’s performance]</li>
</ul>

<h3 id="results">Results</h3>

<p>[Describe the results of your experiments]</p>

<h3 id="visualizations">Visualizations</h3>

<p>[Mention that you’ll add visualizations/examples of the rotated digits]</p>

<h3 id="code-and-implementation">Code and Implementation</h3>

<p>[Brief description of the codebase and implementation details]</p>
